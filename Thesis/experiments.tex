\chapter{Experiment}
\label{sec:experiment}

\newcommand{\takeaway}[1]{
\vspace{6pt}
\noindent\fbox{\parbox{\textwidth}{#1}}
\vspace{6pt}
}
First we would like to evaluate the cost of computing one single IVC using the brute-force
algorithm (\ucbfalg) and the UNSAT core-based algorithm (\ucalg).
Then, we are interested in examining the {\em efficacy} and {\em efficiency} of generating all minimal IVCs, as compared to algorithms for computing a {\em single approximately minimal} IVC (\ucalg\ algorithm), and a {\em minimal IVC} (\ucbfalg\ algorithm).  We would also like to know how performance is affected by the size of models and number of minimal IVCs.  Next, we are also interested in examining the minimality of the cores found by \ucbfalg\ vs  \ucalg . Finally we would like to determine whether the \aivcalg\ algorithm generates {\em smaller} cores than are generated by the \ucbfalg\ algorithm.  %If the AIVC algorithm is similarly efficient to \ucbfalg\ then several analyses can be performed that would not be possible with a single \mivc\computed from the \ucbfalg\ algorithm.
%
%
Therefore, we investigate the following research questions:
\begin{itemize}
  \item \textbf{RQ1:} How expensive is it to compute IVCs?  For this question we examine the cost of the \ucalg ~and \ucbfalg ~algorithms that find a single approximately minimal and guaranteed minimal IVC,respectively, as well as the \aivcalg ~algorithm for determining all minimal IVCs.
  \item \textbf{RQ2:} How is the verification time of the \aivcalg ~algorithm affected by the baseline proof time and the number of IVCs that can be found for a property?
   \item \textbf{RQ3:} How close to minimal are the IVCs computed by \ucalg\ as opposed to the (guaranteed minimal) \ucbfalg\ and the \emph{minimum} IVC computed by \aivcalg ?  How do the sizes of IVCs compare to static slices of the model?
 % \item \textbf{RQ4:} How large are the IVCs produced by the \aivcalg\ algorithm
  %  compared to those of \ucalg\ and \ucbfalg ?
%
%  \item \textbf{RQ3)} How does approximating minimality influence the performance of the \aivcalg ~algorithm?
%  In other words, we would like to determine, for the implementation of the \getivc ~procedure, whether it would be better to use \ucalg ~or \ucbfalg .
%  \item \textbf{RQ4)} How did the pre-set timeout manifest itself in the experimental results?
\end{itemize}


\subsection{Experimental Setup}

Our experiments are conducted on a set of benchmarks containing 660 Lustre models, including all of the benchmark models yielding a valid result (530 in total) from~\cite{Hagen08:FMCAD, piskac2016} and 130 industrial models yielding valid results derived from an infusion pump system \cite{hilt2013} and other sources \cite{piskac2016, NFM2015:backes}.
Most of the academic benchmark models are small (10kB or less, with 6-40 equations) and include a range of hardware benchmarks and software problems involving counters that are difficult to solve inductively.
The industrial models are much larger; for example, each of the 80 problems from the infusion pump \cite{hilt2013} contain over 600 equations and are each $\geq$80kB in size. The benchmark includes 2 models from the NASA Quad-redundant Flight Control System (QFCS)~\cite{NFM2015:backes}: the Flight Control System (FCS) with 5259 Lustre equations and the Flight Control Computer (FCC) with 10969 equations.

We selected only benchmark problems consisting of a Lustre model with
properties that \texttt{JKind} could prove with a 3-hour timeout.
For each test model, we computed \aivcalg, \ucalg, and \ucbfalg ~algorithms in a configuration with the \texttt{Z3} solver and the ``fastest'' mode of \texttt{JKind} (which involves running the $k$-induction and PDR engines in parallel and terminating when a solution is found). The experiments were run on an  Intel(R) i5-4690, 3.50GHz, 16 GB memory machine running Linux, and are available online~\cite{expr}.%\footnote{The benchmarks, tools, and experimental results are available on \cite{expr}.}



\section{Experimental Results}

\input{results} 