\section{Preliminaries}
\label{sec:background}
\newcommand{\satisfies}{\vdash_{\!\!s}}
\newcommand{\nsatisfies}{\nvdash_{\!\!s}}
\newcommand{\bool}[0]{\mathit{bool}}
\newcommand{\reach}[0]{\mathit{R}}
\newcommand{\ite}[3]{\mathit{if}\ {#1}\ \mathit{then}\ {#2}\ \mathit{else}\ {#3}}
\newcommand{\nondetcov}{\text{\sc Nondet-Cov}}
\newcommand{\mutcov}{\text{\sc Mutant-Cov}}

\subsection{Models, Requirements, and Provability}

Given a state space $S$, a transition system $(I,T)$ consists of an
initial state predicate $I : S \to \bool$ and a transition step
predicate $T : S \times S \to \bool$. We define the notion of
reachability for $(I, T)$ as the smallest predicate $\reach : S \to
\bool$ which satisfies the following formulas:
\begin{gather*}
  \forall s.~ I(s) \Rightarrow \reach(s) \\
  \forall s, s'.~ \reach(s) \land T(s, s') \Rightarrow \reach(s')
\end{gather*}
A safety property $P : S \to \bool$ is a state predicate. A safety
property $P$ holds on a transition system $(I, T)$ if it holds on all
reachable states, i.e., $\forall s.~ \reach(s) \Rightarrow P(s)$,
written as $\reach \Rightarrow P$ for short. When this is the case, we
write $(I, T)\vdash P$.
We assume the transition relation of the system has the structure of a top-level conjunction. This assumption gives us a structure that we can easily manipulate. Given $T(s, s') = T_1(s, s') \land \cdots \land T_n(s, s')$ we will write $T = T_1 \land \cdots \land T_n$ for short.
By further abuse of notation we will identify
$T$ with the set of its top-level conjuncts. Thus we will write $x \in
T$ to mean that $x$ is a top-level conjunct of $T$. We will write $S
\subseteq T$ to mean that all top-level conjuncts of $S$ are top-level
conjuncts of $T$.
We will write $T \setminus \{x\}$ to mean $T$
with the top-level conjunct $x$ removed. Such a transition system can easily encode our example model in Section~\ref{sec:example}.  We assume each equation defines a conjunct within the transition system which we will denote by the variable assigned, so $T = \{$ {\small \texttt{a1\_below, a2\_below, a1\_above, a2\_above, below, above\_hyst}} $\}$.
\ela{I leave this here for now. Maybe we should move it later to the place where we're talking about granularity}

\ela{since we are going to submit this paper to a HW oriented community, I think using properties or specification instead of requirements would be better?}

\begin{definition}{\emph{Provability:}}
Let $(I, T)$ be a transition system; given a set of safety properties $\Delta$ and $S \subseteq T$, $r \in \Delta$ is \emph{provable} by $S$ iff
$(I, S) \vdash r$.
\end{definition}

\begin{definition}{\emph{Inductive Validity Cores:}}
  \label{def:ivc}
  Given $(I, T)\vdash r$, $S \subseteq
  T$ is a set of {\em inductive validity cores} for $r$
  iff $r$ is provable by $S$;
\end{definition}

In examining provability, we are interested in {\em minimal} sets that satisfy a property $r$; tracing a property to the entire implementation     \ela{should we say target artifacts instead of implementation?}   is not particularly enlightening.

\begin{definition}{\emph{Minimal Inductive Validity Cores (IVC):}}
  \label{def:minimal-ivc}
  A set of inductive validity cores $S$ for $(I, T)\vdash r$ is minimal, denoted $IVC(r, S)$, iff
  $\neg\exists S' \subset S .\quad (I, S') \vdash r $
\end{definition}

For the sake of simplicity, hereafter, we refer a minimal set of inductive validity cores as an "IVC" set.
Note that there could be many IVC sets for a given property, corresponding to different proofs. To capture that notion, we define \emph{all IVC sets ($AIVC$)} for a property as an association to all its IVC sets.

$$ AIVC(r) \equiv  \{\ S~|~S \subseteq T \land  IVC(r, S)\} $$

%In the example in Fig. \ref{fig:asw}, as visualized in part (b),
%$AIVC ({\tt P}) = \{\{{\tt P}, {\tt c2}, {\tt c3}\}, \{{\tt P}, {\tt x}, {\tt c3}\}\}$.
\noindent The set of $AIVC$-s for all properties represents the complete traceability of the system. Establishing the $AIVC$ for a single property, one gets a clear picture of the all the model elements that are necessary to prove the property.

\subsection{Coverage and Mutations}
In general, specification completeness can be defined with
regard to the notion of coverage. In fact, the way that coverage
is formalized plays a key part in the strength/ effectiveness of
a method for the assessment of completeness. The goal of a coverage metric is usually to assign a numeric score that describes how well properties cover the design. The majority of the work on coverage metrics has focused on {\em mutations}, which are ``atomic'' changes to the design, where the set of possible mutations depends on the notation that is used.  A mutant is ``killed'' if one of the requirements that is satisfied by the original design is violated by the mutated design~\cite{chockler_coverage_2003,chockler2001practical,chockler2010coverage,Kupferman:2006:SCF,kupferman_theory_2008}.  There are Many different kinds of mutations that have been proposed, primarily focused on checking sequential bit-level hardware designs.  For these designs, {\em State-based} mutations flip the value of one of the bits in the state.  There are several variations depending on whether the flip is performed on a single state within a Kripke structure~\cite{hoskote1999coverage}, or in the description of the signal in the transition relation of the circuit~\cite{chockler2001practical}.  {\em Logic-based} mutations fix the value of a bit to constant zero or one, and can be used to determine whether requirements can find stuck-at faults.  {\em Syntactic} mutations~\cite{chockler_coverage_2003} remove states in a control flow graph representation of hardware.  Similarly, for software, it is possible to apply any of the ``standard'' source code mutation operators used for software testing~\cite{Andrews06:mutation} towards requirements coverage analysis.  Some examples of software mutations are:
\begin{enumerate}
    \item Replace an integer constant C by one of $\{0, 1, -1, C + 1, C - 1\}$.
    \item Replace an arithmetic, relational, logical, bitwise logical, increment/decrement, or arithmetic-assignment operator by another operator from the same class.
    \item Negate the decision in an if or while statement
    \item Delete a statement
\end{enumerate}

We assume each element $T_i \in T$ has a set of possible mutations associated with it.  Depending on the modeling formalism used, this may be the value of a gate or signal or an expression within a statement in a program.  We will further assume the existence of a mutation function $f_{m}$ that, given a model element, will return a finite set of mutations for that element.  We can then define the set of mutant models $M$ as follows:
\[
    M = \{ T_i \in T, m \in f_{m}(T_i)\ |\ T \setminus \{T_i\} \cup \{m\} \}
\]

\noindent and then define the mutation score for a set of properties $\Delta$ in the standard way:

\begin{definition} {\emph{Generalized mutation coverage.} } \\
\[
   \mutcov = \frac{ | \{m \in M(T)~|~ m \nvdash \Delta\} |}{|M(T)|}
\]
\end{definition}
\ela{the above definition is missing something. $m \nvdash \Delta$ isn't clear I think}

In our example in Figure~\ref{fig:asw}, applying the software mutations from~\cite{Andrews06:mutation} would involve manipulating the constants used in the definitions of \texttt{a1\_below, a2\_below, a1\_above, a2\_above}, swapping 'or' and 'and' in the definition of \texttt{below, above\_hyst}, or negating the conditions in the if/then/else statements.  Even for this small model, note that there are a large number of possible mutations: 57 given the set defined above, and that this number increases rapidly with the size of the program and the chosen set of mutations.

Of particular interest is the mutation that replaces a computed variable ({\em signal} in hardware) with a ``fresh'' input; this mutation is called a {\em nondeterminism mutation} with a coverage metric called (\nondetcov)~\cite{chockler2010coverage} and is discussed in~\cite{Kupferman:2006:SCF,kupferman_theory_2008,chockler2010coverage}.  If we use an equational transition system to assign the variables, then performing \nondetcov\ coverage an isomorphic operation to removing the defining equation from the set $T$ and checking whether provability is preserved.  In this case, we can dispense with the set $M$ and compute a mutation score much more simply. In one sense, the nondeterminism mutation is the {\em strongest} mutation because it introduces the most additional behaviors into the model, that is, any execution sequence constructed by modifying the assigning equation is also an execution sequence for a nondeterministic mutation.  Equivalently, given a set of universal properties, it is the easiest mutation to ``kill''.  For our example in Figure~\ref{fig:asw}, this mutation would lead to 10 mutations, one for each equation in the model.

\begin{definition} {\emph{Nondeterministic coverage.} }
\label{def:non-det}
$\forall r \in \Delta,\quad T_i \in T$, a nondeterministic coverage can be formalized as a boolean function $\zeta(r, T_i)$. This function maps $r$ and $T_i$ to $true$ iff $r$ covers $T_i$, denoted by $r \rightarrow_{\zeta} T_i$,
 otherwise it returns $false$, denoted by $r \nrightarrow_{\zeta} T_i$.
\end{definition}
\ela{check the above def. I think the notation that Mike said,
$T_i \in \zeta(r)$, makes $zeta$ a relation. but, it's actually a
boolean function with 2 arguments that only returns true or false: $T_i$ is either covered by $r$ or not}

\ela{I want this definition because it makes further formalizations and notations easier and simpler}

\ela{I call the following single mutation, because in addition to be non-det,
each time only one design element gets unconstrained}
\begin{definition} {\emph{Single mutation coverage ~\cite{chockler2010coverage}.} }
\label{def:single-mut}
$\forall r \in \Delta$, $T_i \in T$, $r$ covers $T_i$ iff
$(I, T) \vdash r$ and $(I, T \setminus \{T_i\}) \nvdash r$.
\end{definition}

For the sake of simplicity, we refer to the coverage function
formalized in Definition \ref{def:single-mut} as $\zeta_{sm}$. Using  $\zeta_{sm}$, the coverage score of specification $r$ is computed by
\[
   \frac{ | \{T_i \in T~|~ T \setminus \{T_i\} \nvdash r\} |}{|T|}
\]



