\section{Experiments}
\label{sec:experiments}

We would like to evaluate both the {\em efficiency} and {\em
  effectiveness} of the three described algorithms: \ucalg, \ucbfalg, and \mustalg. Therefore, we investigate the following research questions:
\begin{itemize}
    \item \textbf{RQ1:} How computationally expensive is it to perform coverage analysis using the \ucalg, \ucbfalg, and \mustalg\ algorithms?
    \item \textbf{RQ2:} What are the differences in coverage for different models produced by the \ucalg, \ucbfalg, and \mustalg algorithms?
    \item \textbf{RQ3:} How often does the previously proposed \nondetcov\ metric (\mustalg) not preserve provability?
    %How much does the potential \emph{non-minimality} of \ucalg affect coverage scores?
\end{itemize}

\subsection{Experimental Setup}

To compare our new coverage notion (\ivccov) with previous work (\nondetcovalt), we designed an experiment from a suite of 476 Lustre models from~\cite{Hagen08:FMCAD} augmented
with 81 additional models from some industrial cases ~\cite{QFCS15:backes,hilt2013}. Most of
the benchmark models from~\cite{Hagen08:FMCAD} are small (10kB or less,
with 6-40 equations) and contain a range of hardware benchmarks and
software problems involving counters. The additional models are around 80kB with over 600 equations. Each benchmark model has a single property to analyze.

For each test model, we computed \ucalg, \ucbfalg, and \mustalg in a configuration with
the Z3 solver and the ``fastest'' mode of \texttt{JKind} (which involves running the $k$-induction and PDR engines
in parallel and terminating when a solution is found). The experiments were run on an
Intel(R) i5-4690, 3.50GHz, 16 GB memory machine running Windows 10.

\input{results}


