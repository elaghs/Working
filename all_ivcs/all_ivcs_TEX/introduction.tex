\section{Introduction}
\label{sec:intro}
Most modern sequential model checking techniques for safety properties, including IC3/PDR~\cite{Een2011:PDR} and $k$-induction~\cite{SheeranSS00}, use a form of induction to establish proof.  These techniques are very powerful, and can often reason successfully over very larger or even infinite state spaces.  The proofs provided by these tools provide can provide rigorous evidence that a software or hardware system works as intended.

On the other hand, there many situations in which properties can be proved, but systems still will not perform as intended.  Issues such as vacuity~\cite{}, incorrect environmental assumptions~\cite{}, errors either in English language requirements or formalization~\cite{} can all lead to system failures of ``proved'' systems.  Thus, even if proofs are established, one must approach verification with skepticism.

Recently, Ghassabani et al.~\cite{Ghass16} introduced the idea of {\em inductive validity cores} (IVCs) in order to provide additional information with proofs.  The idea lifts UNSAT cores~\cite{zhang2003extracting} to the level of sequential model checking algorithms using induction.  Informally, if a model is viewed as a conjunction of constraints, a minimal IVC is a set of constraints that is sufficient to construct a proof such that if any constraint is removed, the property is no longer valid. IVCs can be used for several purposes, including performing traceability between requirements and model constraints, assessing model coverage, and explanation of unsatisfiable test obligations when using model checkers for test case generation.%~\mike{should we expand these?}
This work presented two algorithms: \ucalg, which computes an approximately minimal IVC core that is computationally inexpensive, and \ucbfalg, a guaranteed minimal algorithm that is considerably more expensive to compute. %\ela{I have hard time reading the last sentence. Is the grammar correct?}
%
The IVC idea shares many similarities with approaches for computing minimal lemma sets for inductive proofs~\mike{Elaheh: add citations here}, and in fact the \ucalg\ algorithm performs a minimal lemma set computation.  However, there is a substantive difference: to find a guaranteed minimal set of constraints, it is usually necessary to find new proofs involving {\em new lemmas} not used in the original proof, which accounts for the expense of the \ucbfalg\ algorithm.

It is often the case that there are multiple IVCs for a given property.  In this case, the algorithms from~\cite{Ghass16} give, at best, an incomplete picture of the traceability information associated with the proof.  Depending on the model and property to be analyzed, there is often substantial diversity between the IVCs used for proof, and there can be substantial difference in the size between the {\em minimal} IVC returned by the \ucbfalg\ algorithm and a {\em minimum} IVC, which is the (not necessarily unique) smallest IVC.
 If {\em all} IVCs can be found, then several additional analyses can be performed:
\begin{description}
    \item[Impact Analysis:] Given all minimal IVCs, it is possible to determine which requirements may be falsified by changes to the model.  This analysis allows for selective regression verification of tests and proofs: if there are alternate proof paths that do not require the modified portions of the model, then the requirement does not need to be re-verified.
    \item[Robustness Analysis:] As proposed by Murugesan et. al in~\cite{Murugesan16:renext}, it is possible partition the model elements into MUST and MAY sets based on whether they are in every IVC or only some IVCs, respectively.  This may allow insight into the relative importance of different model elements for property.  For example, if the MUST set is empty, then the requirement has been implemented in multiple ways, such as would be expected in a fault-tolerant system.
    \item[Coverage Analysis:] IVCs can be used to define coverage metrics for properties by examining the percentage of model elements required for a proof.  However, since IVCs are not unique, there are multiple, equally legitimate coverage scores possible.  Having all IVCs allows one to define additional metrics: coverage of MAY elements, coverage of MUST elements, as well as policies for the existing IVC metric: e.g., choose the smallest IVC. \ela{I'm not sure if introducing MAY/MUST would make sense to the readers }
\end{description}

\noindent In addition, the Requirements Engineering community is keenly interested in approaches to manage requirements traceability.  In most cases, it is assumed that there is a single ``golden'' set of trace links that describes how requirements are implemented in software~\cite{COEST,"Improving requirements tracing via information retrieval"}.  However, if there are multiple IVCs, then it is possible that there are several equally valid sets of trace links.  Examining the diversity of all IVCs could lead to changes in how traceability is performed and managed in critical systems.

In this paper, we propose a new method for computing \emph{all minimal} IVCs. In  recent  years,  a  number  of  efficient
algorithms  for  extracting  all MUSes  have  been proposed \cite{Bacchus2016, bacchus2015using, belov2012muser2, belov2013core, belov2012towards, nadel2014accelerated, liffiton2005max}.  In this paper, we adapt the recent work by Liffiton et al. \cite{marco2016fast} from the generation of MUSes from UNSAT-cores to all IVCs for inductive model checking.  This requires changing the underlying mechanisms that are used to construct candidate solutions and also changing the structure of the proof of correctness.  In addition, in our proof, we demonstrate that the approach terminates with all minimal IVCs even if the witness generator only generates approximately minimal IVCs (utilizing the ``fast'' algorithm from~\cite{Ghass16}).  In our empirical results, this allows our algorithm to be quite efficient to the extent that in many cases, the cost of extracting all minimal IVCs is similar to the cost of finding a single guaranteed-minimal IVC, and on average is approximately 3x the cost of determining a single minimal IVC.
The contributions of the work are therefore as follows:
\begin{itemize}
    \item An algorithm for computing all minimal IVCs.
    \item A proof of correctness and completeness of the algorithm.
    \item An evaluation of the algorithm for performance and diversity of result sets against a reasonably large benchmark suite. \ela{comparison?}
\end{itemize}

\ela{I think we need to make it clear that IVCs are different from MUSes, proof-certificates or minimal invariants, abstraction, slicing. Currently, the introduction doesn't say anything about these. You had an idea on having a table... Perhaps you want to include a discussion section?\\ Or, Maybe we could expand the introduction with these things and make it more motivating}

\ela{Also, I think the contributions don't stand out. finding \emph{all} \textbf{minimal} IVCs itself is two contribution. I think minimality is important. Maybe we should stress on it a little bit more}

The rest of the paper is organized as follows.
Section \ref{sec:example} introduces a running example used to illustrate concepts and our method.
Section \ref{sec:background} covers the formal preliminaries for the approach.
In Section \ref{sec:allivcs}, we present our method for enumerating all minimal IVCs,
which is illustrated in
Section \ref{sec:illust}. In Section \ref{sec:impl}, we talk about implementation and evaluation of our method. Finally, Section \ref{sec:conc} mentions some conclusions and future work. 