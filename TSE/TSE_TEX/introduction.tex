\section{Introduction}
\label{sec:intro}

Symbolic model checking using induction-based techniques such as IC3/PDR~\cite{Een2011:PDR}, $k$-induction~\cite{SheeranSS00}, and $k$-liveness~\cite{conf/fmcad/ClaessenS12} can often determine whether properties hold of complex finite or infinite-state systems.    Model checking tools are attractive both because they are automated, requiring little or no interaction with the user, and if the answer to a correctness query is negative, they provide a counterexample to the satisfaction of the property.  These counterexamples can be used both to illustrate subtle errors in complex hardware and software designs~\cite{hilt2013,McMillan99:compositional, Miller10:CACM} and to support automated test case generation~\cite{Whalen13:OMCDC, You15:dse}.
In the event that a property is proved, however, it is not always clear what level of assurance should be invested in the result.  Given that these kinds of analyses are performed for safety- and security-critical software, this can lead to overconfidence in the behavior of a fielded system.  Issues such as vacuity~\cite{Kupferman03:Vacuity}, incorrect environmental assumptions~\cite{Whalen07:FMICS}, and errors either in English language requirements or formalization~\cite{Pike06:axioms} can all lead to failures of ``proved'' systems.  Thus, even if proofs are established, one must approach verification with skepticism.

One substantial issue involves the level of feedback provided by the tool to the user. In most tools, when the answer to a correctness query is positive, no further information is provided. What we would like to provide is traceability information, a {\em proof core} that explains the proof, in much the same way that a counterexample explains the
negative result. This is not a new idea: UNSAT cores~\cite{zhang2003extracting} provide the same kind of information for individual SAT or
SMT queries, and this approach has been lifted to bounded analysis
for Alloy~\cite{Torlak08:cores} and has been used for hardware model checking~\cite{jasper_gold}. What we propose is a generic and efficient
mechanism for extracting supporting information, similar to an UNSAT
core, from the proofs of safety and liveness properties using inductive techniques
such as PDR and $k$-induction, which we call an {\em inductive validity core} (IVC). Because many properties are not immediately inductively provable over a given transition system, these proof techniques introduce lemmas as part of the solving process to strengthen the properties to construct inductive proofs. Our techniques allow efficient, accurate, and precise extraction of inductive validity cores even in the presence of such auxiliary lemmas.

\input{motivex}

IVCs are made up of a set of model elements (a notion that will be made precise in Section~\ref{sec:background}).  An IVC is {\em minimal} (MIVC) if no element can be removed and still preserve provability.  Depending on the model and property to be analyzed, there is often significant diversity of possible IVCs used to produce a proof, and there can also be a substantive difference in the size of a {\em minimal} IVC and a {\em minimum} IVC. The minimum IVC is the smallest MIVC, which is not necessarily unique.  Computing a minimum IVC is significantly more difficult than a minimal IVC, because it involves searching through the space of all proofs to find an IVC of (unknown) minimum size.  In this paper, we address this problem by providing algorithms to find both single MIVCs and {\em all} MIVCs, from which the set of minimum IVCs can be extracted.


Once generated, IVCs can be used for many purposes in the software verification process, including:
%\mike{There is something weird with the description environment so I am manually spacing it}

\noindent \textbf{Traceability:} Certification standards for safety-critical systems (e.g.,~\cite{DO178C, MOD:00-55}) usually require {\em traceability matrices} that map high-level requirements to lower-level requirements and (eventually) leaf-level requirements to code or models.  Current traceability approaches involve either manual mappings between requirements and code/models~\cite{SimulinkTraceability} or a heuristic approach involving natural language processing~\cite{Keenan12:Tracelab}.  Both of these approaches tend to be inaccurate.  For functional properties that can be proven with inductive model checkers, inductive validity cores can provide accurate traceability matrices with no user effort.

One important aspect of traceability that is often left unexamined is that of {\em diversity}.  Often there are multiple traceability matrices that could equally well be represent functional traceability (at least, in terms of proof).  Computing all MIVCs exposes this diversity and may lead to a more complete understanding of system behavior.  Conversely, a single MIVC may not provide a complete understanding of traceability.

\noindent \textbf{Vacuity detection:} The idea of syntactic vacuity detection (checking whether all subformulae within a property are necessary for its validity) has been well studied~\cite{Kupferman03:Vacuity}.   IVCs allow a generalized notion of vacuity that can indicate weak or mis-specified properties even when a property is syntactically non-vacuous.   This kind of mis-specification occurs regularly, especially when variables computed by the model are used as elements of antecedents in implicative properties.

\noindent \textbf{Coverage analysis:} Closely related to vacuity detection is the idea of {\em coverage analysis}, e.g., are all atoms in the model necessary for at least one of the properties proven about the model?  Several different notions of coverage have been proposed~\cite{chockler_coverage_2003, kupferman_theory_2008}, but these tend to be very expensive to compute, and in some cases, can only be used for certain kinds of models (e.g., checking can only be performed on non-vacuous models~\cite{kupferman_theory_2008}).

\noindent \textbf{Impact Analysis:} Given a single MIVC, or for more accurate results, all MIVCs, it is possible to determine which requirements may be falsified by changes to the model.  This analysis allows for selective regression verification of tests and proofs: if there are alternate proof paths that do not require the modified portions of the model, then the requirement does not need to be re-verified.

\noindent \textbf{Symbolic Simulation/ Test Case Generation:} Model checkers are now often used for symbolic simulation and structural-coverage-based test case generation~\cite{SimulinkDesignVerifier,Whalen13:OMCDC}.  For either of these purposes, the model checker is supposed to produce a witness trace for a given coverage obligation using a {\em trap property} which is expected to be falsifiable.  In systems of sufficient size, there is often dead code that cannot ever be reached.  In this case, a proof of non-reachability is produced, and the IVC provides the reason as to why this code is unreachable.

\noindent \textbf{Design Optimization:} Synthesis tools can benefit from MIVCs in the process of transforming an abstract behavior into a design implementation. A practical way of calculating all MIVCs allows synthesizers to find a minimum set of design elements for a certain behavior. Such optimizations can be performed at different levels of synthesis.

To be useful for these tasks, the generation process must be efficient and the generated IVC must be accurate and precise (that is, sound and close to minimal).  The requirement for accuracy is obvious; otherwise the set of model elements is no longer sufficient to produce a proof, so it no longer meets our IVC definition.  Minimality is important because (for traceability) we do not want unnecessary model elements in the trace matrix, and (for completeness) it may give us a false level of confidence that we have enough requirements.

The goal of this paper is to provide a definitive and comprehensive explanation of algorithms and applications for inductive validity cores.  It provides a unified treatment of material from four conference papers~\cite{Ghass16,Murugesan16:renext,Ghass17Cov,Ghass17AllIVCs}.  Additionally, it contains (1) a significantly larger experiment than previous work, both in terms of the number of models (660 vs. 476) that is a superset of a large benchmark suite used to evaluate model checking tools~\cite{piskac2016}, with the number of large models (containing more than 100 equations) increased from 81 to 130, (2) an expanded treatment of traceability and its use in certification, (3) a discussion of {\em granularity} of model elements and how this affects traceability information, especially in regards to coverage of requirements, and (4) revised, more detailed proofs that correct a handful of clerical mistakes in previous papers.


The remainder of the paper is organized as follows: Section~\ref{sec:example} provides a running example that will be used to illustrate concepts in the remainder of the paper.  Section~\ref{sec:background} provides formal preliminaries.  Section~\ref{sec:ivc} describes inductive validity cores and provides algorithms for both generating a single IVC and all IVCs.  Section~\ref{sec:impl} describes the implementation.  Section~\ref{sec:experiment} describes an experiment that examines fitness for purpose of the different IVC algorithms.  Section~\ref{sec:apps} describes applications of IVCs for different software engineering purposes.   Finally, Section~\ref{sec:related} discusses related work and Section~\ref{sec:conc} concludes.

%The remainder of the paper is organized as follows...
