\section{Related work}
\label{sec:related}

\mike{integrate into related work!}
Instead, to measure completeness, several surrogate models to measure completeness have been proposed.  Zowghi and Gervasi use refinement to show {\em relative completeness} with respect to a {\em domain} model, which describes the behavior of the real world, irrespective of change induced by software.  In their model, each iteration of refinement of requirements and domain models must be sufficient to prove the requirements of the previous iteration.  However, this idea has two problems: first it provides no notion of absolute completeness, and second, it requires construction of a domain model, which is often difficult and/or expensive to construct.


The notion of coverage has been defined in different ways in the context of property-based verification \cite{chockler2008causes, chockler2006coverage, chockler_coverage_2003, katz1999have, grosse2007estimating, claessen2007coverage}.
Coverage in verification was introduced in \cite{hoskote1999coverage, katz1999have}. Hoskote et al. \cite{hoskote1999coverage} suggested a state-based metric in model checking based on FSM mutations, which are small atomic changes to the design. Then, the method for measuring coverage is to model check a given property for each mutant design.
Later in \cite{chockler_coverage_2003}, Chockler et al. provided corresponding notions of metrics used in simulation-based verification for formal verification. In fact, they improved the same idea of mutation-based coverage where each mutation is generated to check if a specific
design element is necessary for the proof of the property.
 However, the proposed metric is not only very computationally expensive, but also is not able to identify \emph{may} elements of the design. That is, if the proof requires a set of IVC made of two disjoint sets of \emph{may} and \emph{must}, which both play a part in the validity of the property, their technique can only specified the \emph{must} set. It should be pointed out that most of the mutation-based metrics, including \cite{kupferman_theory_2008, chockler2001practical}, are focused on finite state systems.

 MORE ON \cite{Kupferman:2006:SCF} fill in later...

A more recent work in \cite{chockler2010coverage} performs coverage analysis through interpolation \cite{mcmillan2003interpolation}. This work is also based on design-dependent mutations \cite{chockler_coverage_2003}, where a design is considered as a net-list with nodes of types \{AND, INVERTER, REGISTER, INPUT\}. Each mutant design changes the type of a single node to INPUT. When property $\phi$ satisfied by the original net-list fails on the mutant design, it is said that a mutant is discovered for $\phi$, which is the same as a \emph{must} element.
Then, the coverage metric for $\phi$ is defined as the fraction of the discovered mutants, based on which the coverage of a set of properties is measured as the fraction of mutants discovered by at least one property.
In order to decrease the cost of computation, the check is performed at several stages; first, all the nodes that do not appear in the resolution proof of a given property are marked as \emph{not-covered}, and the rest of the nodes are marked as \emph{unknown}. Then, for the unknown nodes, the basic mutation check is performed: if a corresponding mutant design violates the property, it will be considered as \emph{covered}. Otherwise, the algorithm tries to drive an inductive invariant to prove that the node is not covered. Finally, an interpolant-based model checking is applied to the nodes that are still unknown.

A Different approach to measure coverage in formal verification is to check each output signal is fully constrained by the specification \cite{das2005formal, claessen2007coverage, grosse2007estimating}, which is not related to the mutation coverage. For example, in In \cite{claessen2007coverage}, authors proposed a design-independent coverage analysis where a forgotten property is identified by an uncovered output signal. This method investigates, given a property list and a specific output signal $s$, if there is a trace with a point in time when a particular $s$ is not constrained by any properties. Another work in \cite{haedicke2012guiding} defines a coverage metric that computes a numerical value to describe how much of the circuit behavior is constrained by a given set of properties.
%This methods investigates, given property $\phi$ and a specific output $s$, if there exist two traces $\sigma_{1}$ and $\sigma_{2}$ that: (1) $\sigma_{1} \vDash \phi$ and $\sigma_{2} \vDash \phi$ (2) $\forall$ signals &s' \neq s, \forall t. \sigma_{1}(t, s') = \sigma_{2}(t, s')& (3) &\exists t. \sigma_{1}(t, s) \neq \sigma_{2}(t, s)&. This method was implemented in SMV model checker \cite{smv}.

MORE RECENT: \cite{yang2013minimal} \cite{chockler2011incremental} \cite{brillout2009mutation} \cite{bao2014coverage}

MORE:

Espana et al. \cite{espana2009evaluating} also studied the granularity and completeness of specification by defining some metrics to measure completeness. However, their approach is empirical and not in the context of formal verification.

\cite{drechsler2012completeness, firesmith2005your, chang2007finding,katta2013investigating, zowghi2002three} : not in the model checking area

\cite{Whalen07:FMICS} ...
